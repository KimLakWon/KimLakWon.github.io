---
title: "운영체제 개념 정리"

date: 2019-05-25 18:01:28 -0400

categories: jekyll update

---

## 운영체제

# 1. Intorduction to Operating Systems

 1) 폰 노이만 모델 : 메모리에서 한 명령문을 Fetch(추출) -> Decode(해석) -> Execute(실행) -> 다음 명령문으로 가서 반복
 2) OS의 역할
  - Virtualization(가상화) : 물리적인 장치를 더욱 강력하게, 편리하기, 동시에 사용할 수 있도록해준다. 시스템 콜을 부를 수 있다.
  - 가상화는 1개의 CPU와 1개의 메모리가 여러개인 것 처럼 보이게 해준다.
  - Resource Manager(자원 관리자) : CPU, 메모리 등을 효율적으로 관리한다.
  - Concurrency(동시성) 문제 해결 : 멀티 쓰레드 등을 사용해서 동시성 문제를 해결한다
  - Persistence(지속성) 문제 해결 : 파일 시스템 등을 사용해서 휘발성 데이터들을 영구적으로 보관한다.

2. Limited Direct Execution

 1) OS는 가상화를 수행하면서 시스템 권한을 잘 제어해야 한다.

 2) 문제 1 : Restriced Operations
  - 각각 프로그램이 자신에게 할당된 자원을 넘어가지 못하도록 접근을 금지해야한다.
  - 만약 넘어간다면, 그 프로그램이 무한히 돈다면 OS는 평생 주도권이 없을 것이다.
  - 하드웨어의 2가지 모드를 이용한다. User mode는 사용자 프로그램 모드이고, Kernal mode는 OS의 모든 권한을 가진 모드이다.
  - User mode에서 권한 밖의 기능을 사용할 일이 있을 때, System Call을 부른다. (그렇지 않으면 걍 Kill 해버림)
  - System Call이 불리면, Trap이 호출되어 현재 명령어 주소를 Kernel 영역으로 옮긴다. (커널 스택에 레지스터 정보 저장)
  - 이제 System Call Number를 Trap table에서 찾아 해당 주소로 이동하다.
  - Kernel 영역이기 때문에 해당 작업(ex. 파일쓰기)을 수행할 수 있다.
  - 해당 작업이 종료 되었다면, return-from-trap 명령어를 실행시켜서 User mode로 옮기고, System call을 호출 했던 다음 명령어(PC:Program Counter)로 이동한다.
  - 시간 흐름도 : 어플 -> syscall -> trap handler가 trap table를 읽음 -> trap table의 kernel code 실행 -> 어플
  - 데이터 흐름도 : A에서 커널 스택으로 -> 커널 스택에서 PCB-A으로 -> PCB-B에서 커널 스택으로 -> 커널 스택에서 B로
 
 3) 인터럽트
  - H/W와 S/W 모두로 부터 오는 예기치 못한 이벤트.
  - 현재 작업하던 것을 멈추고 인터럽트 핸들러를 호출해, 소재를 파악하고 방안을 탐색하여 ISR(Interrupt Service Routine)을 실행시킨다.
  - 인터럽트 실행 중에 인터럽트가 발생한다면?  = Lock을 이용하자!

 4) 문제 2 : Switching Between Process
  - 어떻게 여러가지 프로세스를 바꿔주며 제어해야할까?
  - 비선점(Cooperative) : OS는 System call이 오기까지 기다리는데, 만약 프로그램이 버그로 가득찼다면 망..
  - 선점(Non-Cooperative) : OS는 System call이 오지 않아도 주도권을 가진다. 그 방법은 Timer를 사용해 인터럽트를 주기적으로 발생시킨다. (그때마다 실행 프로세스를 결정한다)

 5) Context Switch (문맥 교환)
  - 인터럽트가 발생되고 다른 프로세스를 거쳐와도 기존의 정보들이 모두 저장되어 있어야한다.
  - 별도의 proc-structure에 안전하게 저장되어 다시 running되면 정상적으로 복구가 된다.
  - Process P0은 PCB 0에 저장되고, 나중에 Process P0이 실행되면 PCB 0에서 데이터를 꺼내옴
  - 이는 오버헤드를 발생시켜 속도가 느려지게 하지만, '스케쥴링'을 통해 어느정도 완화할 수 있다.
 
3. Process

 1) Process의 개념
  - Process는 실행하고 있는 프로그램이고, 프로그램은 저장소에 저장되어있는 명령어의 집합이고, 프로세서는 CPU.
  - 프로세스는 커널에 의해 관리되고 등록된다.
  - PCB(Process Control Block) : 커널에 등록된 각각의 프로세스의 기본 정보들을 저장하는 곳.
  - 프로세스 = 메모리 + 레지스터들 + I/O 정보

 2) Process API
  - Create(만드는거), Destroy(없애는거), Wait(기다리는거)
  - Miscellaneous Control : 프로세스를 멈추거나 실행시키는거 (ex. running <-> ready 이런거)
  - Status : 상태 정보들을 뜻함.

 3) Process States
  - Runnnig : 실행하고 있는 중
  - Ready : 기다리고 있는 중, CPU를 제외한 모든 자원을 할당받은 상태.
  - Blocked : I/O 같은 다른 일을 처리 중, CPU를 사용할 수 없음

 4) PCB의 정보
  - PID, state, PC, CPU 레지스터들, 스케쥴링 정보, 메모리나 I/O 정보들
  - PCB의 구조는 OS 마다 다르다.
  - PCB의 접근 속도가 시스템의 전반적인 성능을 결정한다.

 5) Process Creation API
  - fork() : 새로운 자식 프로세스를 생성, 부모프로세스에게 자신의 pid를 리턴, 자식은 0.
  - exec() : fork() 후에 부모 프로세스의 메모리를 자식 프로세스가 사용하도록 함
  - wait() : 부모 프로세스는 자식이 죽을때까지 기다림
  - exit() : 프로세스 종료, 죽은 상태를 부모프로세스에게 전달.
  - 부모는 자식이 더이상 필요가 없으면 죽인다.
  - zombie process : 자식이 죽었는데 부모가 wait을 부르지 않음..
  - 좀비 프로세스는 OS가 찾아서 다 죽인다.
  - orphan process : 부모가 자식 만들고 wait 없이 죽음..
  - 고아 프로세스는 최상위 init 프로세스가 다 입양하고 죽인다. (?)

4. Scheduling

 1) Multiprogramming
  - CPU가 항상 어떠한 프로세스를 작업하게 함으로써, CPU 점유율을 증가시킨다.
  - 시간과 메모리를 잘 공유해야 한다.

 2) 성능 지표
  - Turnaround time : 특정 CPU가 실행되는데 걸리는 시간
  - Respond time : 프로세스가 스케쥴링 큐에 도착하고, CPU에 점유되는데 까지 걸리는 시간

 3) FCFS(First-Come-First-Service) = FIFO
  - 비선점 스케쥴링
  - 무조건 선착순
  - 장점 : 문맥교환이 없어서 자원 점유율이 높음.
  - 단점 : 실행시간이 짧은 애가 와도 긴 애를 계속 기다려야됨..

 4) SJF(Shortest Job First)
  - 비선점 스케쥴링
  - 시간이 짧은애 먼저
  - 장점 : 기다리는 시간 최소, 대기중인 애들 최소
  - 단점 : Stavation 문제 발생 (짧은 애가 계속 오면, 긴 애는 계속 기다려야됨..), 다음 프로세스의 시간을 알 수가 없음

 5) STCF(Shortest Time-to-Completion First)
  - 선점 스케쥴링
  - 남아있는 시간이 짧은애 먼저
  - 장점 : SJF랑 같음
  - 단점 : 문맥교환 오버헤드가 많고, Stavation 아직 남아있음

 6) RR(Round-Robin)
  - 선점 스케쥴링
  - 매 시간마다 돌려가며 함. (일단은 먼저 온 애부터)
  - time slice가 크면 FCFS랑 다를게 없음
  - time slice가 작다면 문맥교환을 너무 자주해야돼서 성능에 문제
  - Stavation 문제 해결

 7) MLFQ(Multi-Level-Feedback-Queue)
  - 선점 스케쥴링
  - 우선순위가 다른 스케쥴링 큐를 여러개 이용함
  - 룰1 : 우선순위 높은거 먼저, 같으면 RR
  - 룰2 : 새로운 프로세스는 가장 높은 우선순위
  - 룰3 : 시간을 다 쓰면 우선순위 내려감, 시간을 다 쓰기전에 끝나면 우선순위 유지
  - 룰4 : 프로세스가 점유한 전체 시간을 바탕으로 우선순위 결정 (짧은 애들 불이익줌)
  - 룰5 : 특정 시간마다 모든 프로세스를 최우선순위로 올림 (꼼수 방지)
  - 시간이 지날수록 지수적으로 Time uantum이 늘어남. (1-2-4-8...)

 8) Multiprocessor Scheduling
  - SQMS (Single Queue Multiprocessor Scheduling) : 1개의 큐
  - MQMS (Multi Queue Multiprocessor Scheduling) : CPU 1개당 1개의 큐
  - Migration : MQMS에서 큐의 격차를 해소하기 위해서 비어있는 큐로 이동시킨다.

5. Memory

 1) Address space
  - 사용자들이 멀티 프로세스를 원하면서 Time Sharing과 Protection의 개념이 생겨났다.
  - Time Sharing은 CPU를 번갈아 사용하는 것인데 문맥 교환의 오버헤드를 줄이는게 목표다. (스케쥴링..)
  - Protection은 서로의 프로세스가 서로의 범위를 침범하지 않도록 방어하는것을 의미한다.
  - 그렇기 때문에 OS는 각 프로세스에게 가상의 메모리 범위를 제공한다.
  - 각 프로세스는 자신만이 사용할 수 있는 공간이라고 착각하도록 만든다. 
  - Address Binding : 가상 주소를 실제 주소로 변환하는 과정

 2) Virtualizing의 목적은?
  - Transparency(투명성) : 각 프로그램은 다른 범위가 있다는 사실을 몰라야한다. (침범할 수 있기에)
  - Efficient(효율성) : 가상 메모리를 사용하는데 너무 많은 시간이 걸리거나 과도한 공간을 사용하면 안된다. (H/W가 도와줌)
  - Protection(보호) : 모든 프로세스는 isolation 상태여야한다. 다른 프로세스에 영향을 미쳐선 안된다.
  - 하지만 이는 멀티쓰레드 환경에서는 좋은 방식은 아니다. (나중에..)

 3) Relocation
  - Absolute Relocation : 컴파일 타임에 바인딩을 하는 것으로, 컴파일 하면서 물리적 주소를 정함
  - Static Relocation : 로드 타임에 바인딩을 하는 것으로, 컴파일때는 시작주소가 0임.
  - Dynamic Relocation : 실행 타임에 바인딩을 하는 것으로	실행하면서 MMU에서 주소를 번역해준다. 
  - 요즘 OS는 Dynamic Relocation을 사용한다.
  - MMU(Memory Management Unit) : 가상 주소를 물리 주소로 바꾸어주는 CPU의 장치

 4) Dynamic Loading & Linking
  - Dynamic Loading : 주소 바인딩 시간을 최대로 늦춰서 메모리 활용에 도움. 프로세스 주소가 물리주소보다 커도 됨
  - Dynamic Linking : 1개의 라이브러리로 여러 프로세스에 추가할 수 있어서 메모리 낭비를 줄일 수 있다.
  - 근데 동적 링킹은 하나의 라이브러리를 공유하기 때문에 프로세스들끼리 주소 공간 문제가 발생할 수 있다.

 5) Fragmentation
  - Internal Fragmentation : 프레그먼트 안에서 공간이 남는경우. 생각보다 크기가 작아서..
  - External Fragmentation : 프로세스가 프레그먼트보다 커서 안들어가는 경우.. 프레그먼트 사이에 공간이 너무 작음

 6) 연속 메모리 할당의 교체 전략
  - First-fit : 첫번째로 발견한 교체 가능한 크기의 파티션을 할당 (시간이 오래걸림)
  - Best-fit : 정렬해 놓고, 교체 가능한 크기인데 가장 작은 파티션을 할당 (External Fragmentation 유발)
  - Worst-fit : 정렬해 놓고, 가장 큰 파티션을 무조건 할당. (성능이 너무 안좋음)
  - Next-fit : 아까 발견한거부터 시작해서 교체 가능한 크기의 파티션을 할당 (오버헤드 적음)
  - 주로 First-fit이나 Best-fit, Next-fit을 사용함.

 7) 연속 메모리 할당의 메모리 관리
  - Coalescing holes : 연속되는데 나눠진 Fragmentation을 합침
  - Compaction : 중간 중간 남는 것들 모아서 합침
  - 버디 알고리즘 : 큰 버퍼들을 반복적으로 이등분하여 작은 버퍼를 만들어서, 인접한 free 버퍼와 합치는 기법

 8) Segmentation (비연속 메모리 할당)
  - 작게 나눠서 할당해주는거임. (테이블에 근거해서)
  - segmentation table의 limit > offset이면 매핑이 가능하다는 소리.
  - 그러면 segmentation table의 base + offset이 pysical address가 되어 할당됨.
  - Segment, Base, Size, Grow Positive, Protection 으로 이루어짐.
  - Segmentation은 사이즈를 다르게 줘서 외부 단편화는 없애지만, 내부 단편화는 남아있다.

6. Paging

 1) Page
  - 가상 주소공간을 고정된 사이즈(Block)으로 나눈 것이 Page이다.
  - 물리 주소공간을 고정된 사이즈(Block)으로 나눈 것은 Frame이다.
  - 가상 -> 물리 주소공간으로 번역하기 위해서는 Page Table이 필요하다.
  - Page를 이용하면 주소공간을 연속적으로 할당할 필요가 없으니, External Fragmentation을 없앨 수 있다.
  - 가상 공산(Page) -> Page Table(매칭) -> 물리 공간(Frame)
  - 가상 공간 = page number(Page table entry number) + page offset(d)
  - page size는 주로 4KB ~ 8KB 이다.
  - PTBR(Page Table Base Register) : Page Table의 시작주소 레지스터이다.
  - PTLR(Page Table Limit Register) : Page Table의 사이즈를 가지는 레지스터다. (메모리 보호를 위해)
  - Page Table은 프로세스당 1개가 존재한다. (가상주소이므로)
  - Page Table = frame number, valid-invalid bit, dirty bit, protection bit ...
  - Page Table은 사이즈가 커서 RAM에 저장되고, MMU에는 TLB cache가 있다.

 2) TLB (Translation Look-aside Buffer)
  - TLB cache는 64~1024개의 entry를 가진다. (작은 용량)
  - TLB 안에서 매칭이 되면 'TLB hit'가 돼서 바로 물리 주소로 찾아갈 수 있다.
  - TLB 안에서 매칭이 안되면 'TLB miss'가 돼서 Page Table에서 값을 찾아서 TLB로 옮긴다.
  - TLB hit는 메모리 접근 시간 1이라서 효율이 좋다.
  - TLB가 꽉 찼을 때 Replacement 정책을 잘 고려해야 한다.
  - TLB 에는 ASIDs(Address-Space Identifiers)가 있는데, 프로세스마다 다른 id의 Page Table을 구분한다. (PID랑 비슷)

 3) Shared Page
  - Page 단위로 다른 프로세스끼리도 서로 공유하자. (특히 읽기 전용인거)
  - Code, Data, Stack은 공유 X
  - 공유되는 Page는 같은 Frame을 공유하는 거임.

 4) Page Table
  - Page 엔트리가 4byte라고 했을 때, 백만개면 테이블만 4MB이다. 줄일 수 없을까?
  - Bigger Pages : 페이지를 크게하면 테이블의 크기는 줄어들지만, TLB의 커버범위가 늘어나고, 내부단편화가 심하다.
  - Paging and Segments : 페이지로도 나누고, 세그먼트로도 나누자. (도, 시 이렇게?)
  - 하지만 이건 낭비가 심하고 외부 단편화가 생김
  - Multi-level Page Table : Page Directory를 만들어서 일부만 할당한다.
  - 공간적으로는 좋지만, Level이 높아지면 메모리 접근 시간이 증가되어 성능이 안좋아진다.
  - Hashed Page Table : 32비트보다 더 다뤄야할 주소 공간이 클 때 사용한다.
  - 같은 주소를 참조하는 키는 Chaining으로 연결한다.
  - Inverted Page Table(IPT) : 완전 뒤바꿔서, 페이지 프레임 넘버로 가상 메모리 내부의 페이지를 찾는 방법..

7. Page Replacement

 1) Page Fault
  - MMU에서 페이지 번역을 하려는데, 그 엔트리의 valid-invalid bit가 i일 경우에 Page Fault..
  - 찾는 페이지가 메모리에 존재하지 않는다는 뜻임.
  - 만약 Page Fault가 일어나면, trap이 발생해, OS가 디스크에서 그 페이지를 Swap in 해옴.
  - 그리고 물리 주소 중에 free frame을 찾아서 Page Table에 등록함.

 2) Page Replacement
  - Page Fault가 발생했을 때, Free frame이 없을 때, 우리는 어떤 페이지를 교체할 지 찾아야함.
  - 그 교체되는 페이지는 victim page이고 디스크로 swap out 됨.
  - FIFO : 가장 처음에 사용했던 페이지를 바꾸자
  - FIFO는 Page Frame 수가 많아질수록 점점 Page Fault가 증가하는 Anomaly가 있다..
  - MIN(OPT) : 앞으로 안 쓰일 Page를 바꾸자. (현실적으로 가능?)
  - LRU(Least Recently Used) : 가장 오랫동안 사용되지 않았던 페이지를 바꾸자 (실용적)
  - LRU는 지역성을 바탕으로 둔 알고리즘, Stack으로 구현..
  - Clock algorithm, Enhanced Clock algorithm : 참조비트와 clock을 이용함.
  - RAND : 그냥 랜덤... (Loop는 LRU보다 RAND가 좋다는..)

 3) Thrashing
  - 만약 프로세스가 충분한 페이지를 가지지 못할 때, Page fault는 급증한다.
  - 멀티 프로세싱이 많아질 수록 CPU 점유율이 증가하다가, 갑자기 확 떨어지는 시기가 생김
  - 계속 Swap in-out만 하는거임..
  - A를 Out 시켰는데 바로 그 A가 필요하대, 그래서 B를 Out 시켰는데 그 B가 또 필요하대..

 4) Working set
  - 주어진 시간 안에 프로세스가 참조하는 페이지 프레임 집합.
  - 그니까 자주 사용하는 애들이라는 뜻.

 5) Overlay
  - 프로그램 용량 > 메모리 용량
  - 관련 깊은것끼리만 묶어서 따로 모듈로 나누어 수행

 6) page out daemon
  - Swapping 과 Paging을 관리하는 별도의 커널 스레드
  - 메모리 부족을 나타내는 임계치에 다달하면 활동한다.
  - H/W

 7) Copy-On-Write (COW)
  - 여러 프로세스가 평소 자원을 공유하다가 수정할 경우가 발생되면 이전 자원의 복사본을 사용하는 방법.
  - 이 후에 각각의 프로세스의 포인터를 변경시켜주면 된다.
  - 멀티스레드가 도입되면서부터는 Copy와 Write를 동시에 처리한다..

8. Thread

 1) Thread(쓰레드)
  - 같은 주소 공간을 공유하므로, 같은 데이터에 접근할 수 있다.
  - TCB(Thread Control Block)에서 쓰레드끼리의 문맥 교환이 일어난다.
  - 각 쓰레드마다 자신의 Stack, 레지스터(PC), 기타 정보 등이 있고 데이터나 코드는 공유한다.
  - 장점 : 동일한 프로세스의 메모리 공유, 프로세스 전환보다 빠르다, 멀티 프로세서에서 병렬 실행에 좋다.
  - 단점 : 순서가 명확하지 않아 생기는 문제점들..

 2) Race Condition(경쟁 조건)
  - 두 개 이상의 스레드들이 공유된 자원에 접근하려고 할 때 동기화 메커니즘 없이 접근하는 상황
  - 하나의 자원을 놓고 경쟁함. 
  - 실행 순서를 잘 정해놓지 않으면 비정상적인 결과가 나올 수 있음. (간헐적으로 나옴;;)
  - Atomic하게 해주면 된다.

 3) Critical Section (임계 영역)
  - 공유되는 자원, 즉 동시에 접근하려고 하는 그 포커싱 된 자원에서 문제가 발생하지 않게 독점을 보장해줘야하는 영역
  - 제어를 잘 해줘야 되는 영역..
  - 해결 방법 : Lock, Semaphore, Monitor 등 ...

 4) Mutual Exclusion (상호 배제, Mutex)
  - 공유되는 자원의 동시 사용을 피하기 위해서 사용하는 알고리즘
  - Critical Section의 코드 영역에 구현된다.

 5) Thread API
  - Pthreads : POSIX 표준, 유닉스나 리눅스에서 컴파일할 때 넣어줘야함, User Thread임.
  - pthread_create( 쓰레드 주소, attr, 실행할 함수, arg)
  - pthread_mutex_t : 락을 의미함.
  - pthread_mutex_lock(락 주소) : 락을 거는거
  - pthread_mutex_unlock(락 주소) : 락을 푸는거
  - pthread_cond_t : 신호를 의미함.
  - pthread_cond_wait(신호 주소, 락 주소) : 신호가 올 때 까지 기다림
  - pthread_cond_signal(상태 주소) : 신호를 보냄

 6) Thread Pools
  - 스레드를 미리 만들어 놓은 풀장.
  - 필요할 때마다 만들면 성능이 안좋으니까, 한번에 만들어놨다가 필요할 때 가져와서 써먹는다.
  - 특히, 대규모 프로젝트에서 서비스측면에서 볼 때 중요하다.
  - 단점 : 메모리 낭비 조심, 유휴시간 발생 가능

9. Locks

 1) Lock
  - 내가 자원을 사용하고 있을 동안에 문을 잠궈놓고 아무도 못들어오게 하는 방식.
  - 경쟁 조건 문제를 해결할 수 있다.

 2) Spin-Lock
  - while문으로 lock이 풀릴 때 까지 계속 돌고 있는것
  - 락을 얻었는지 확인하면서 얻을 때 까지 기다리는 것.
  - CPU를 계속 차지하니까 굉장히 비효율적.
  - 하드웨어의 automic 명령문을 이용한다.
  - 피터슨 알고리즘 : flag를 이용하는건데 요즘은 안씀 
  - test-and-set : 새로 받은 것을 저장하고, 원래 있던 것을 반환한다.
  - compare-and-exchange : 기대 값과 맞으면 새롭게 저장. 원래 값 반환
  - Load-linked and Store-Conditional : 링크할 때까지 업데이트가 안됐으면 성공, 업데이트 됐으면 실패
  - Fetch-and-Add : 번호표 뽑고 기다림.
 
 3) Yield
  - 스핀을 돌지말고, 나한테 락이 없으면 걍 포기하고 CPU 넘겨주기.
  - 문맥 교환 비용이 많이 들음.
  - 기아 문제 발생 : 우선순위 낮은애는 계속 양보만 해서 굶어 죽는거..

 4) Lock with Queue
  - 큐에 대기자를 넣어서 기다리게 함.
  - 락을 사용하던 애가 완료를 하면 자기 뒤에서 기다리던 애를 깨워줌.
  - 효율적이고, 기아 문제 해결(순서가 있으니까)

10. Condition Variables

 1) Condition Variables
  - 특정 조건에 따라 쓰레드의 실행을 중지하거나 다시 실행시키는 역할을 하는 동기화 장치
  - 특별한 변수를 만들어 이 조건변수가 신호를 받을 때 까지 기다림.
  - 신호를 받으면 깨어나서 동작함.
  - 경쟁 조건 문제를 해결하기 위해 락이랑 같이 쓰임. (만약 락을 안걸어주면 신호를 계속 기다리는 상황이 발생될 수도 있음)
  - wait() : 락을 넘겨주고 잠자러감.
  - signal() : 기다리고 있는 모든 쓰레드 중에 하나를 임의로 선택해서 깨움 (못정함), 아무도 안기다리면 아무일도 안일어남
  - 문제점 : 락이 필요하며, 작업이 종료되었는지를 판별하는 변수도 필요하다...

 2) Producer/Consumer Problem
  - Producer : 생산자로 데이터 아이템을 생산해서 버퍼에 넣는다.
  - Consumer : 소비자로 버퍼에 있는 데이터 아이템을 소비한다.
  - Bounded buffer : 공유 자원으로 동기화 접근이 필요한 유한 버퍼

 3) #Problem 1
  - 소비자가 연속으로 일어나버리면 비어있는 버퍼에서 꺼내는 문제 발생..
  - 해결 방법 : if를 while로 변경하여, 버퍼에 아이템이 남아있는지 다시 확인
 4) #Problem 2
  - 근데 생산자가 생산자를 깨우거나, 소비자가 소비자를 깨우면 영원히 잠잔다.
  - 해결 방법 : 컨디션 변수 2개(fill,empty)를 이용해서 생산자 <-> 소비자를 깨우게 한다.
 5) 추가 성능 
  - 버퍼를 더 크게 만들어서 문맥 교환을 최소화 시키자.
 6) #Problem 3
  - 근데 누굴 깨울지 모르기 때문에 원하는 놈이 깰 때까지 계속 기다려야한다...
  - 해결 방법 : 세마포어

11. Semaphore

 1) Semaphore(세마포어)
  - 다익스트라가 만든 엄청난 기법 (모든 것을 구현 가능)
  - wait과 post가 원자적으로 실행된다.
  - 두 번째 인자는 0- 쓰레드 간 공유, 그 외 - 프로세스 간 공유를 뜻한다
  - 세번째인자는 초기값을 의미한다.
  - 세마포어의 값은 자물쇠의 개수를 의미한다. 마이너스는 기다리고 있는 사람 수를 의미한다.
  - 락 = 이진 세마포어
  - sem_post : 세마포어를 증가시킴 -> 안에 있던 사람이 일을 마치고 나와서 자물쇠를 하나 건네준다는 뜻임
  - sem_wait : 세마포어를 감소시킴 -> 일하러 사람이 옴. 만약 자물쇠가 있다면(>=1) 감소하고 들어감, 만약 자물쇠가 없다면 (<=0) 감소하고 기다림

 2) Producer/Consumer Problem With Semaphore
  - 세마포어 3개로 풀 수 있다. (empty, full, mutex)
  - mutex는 empty와 full의 안 쪽에다 걸어줘야 한다. (안그러면 deadlock 걸림..)
  - 만약에 소비자가 mutex 자물쇠를 가져가고 full 자물쇠가 오기를 기다림 (버퍼가 차기를 기다림)
  - 생산자는 이제 생산을 하려고 했는데 mutex 자물쇠가 없어서 방에 못들어감;;;
  - 그니까 창고 문 잠가놓고 창고에 물건 들어오기를 기다리는거임;;

 3) Dining Philosopher
  - 철학자들이 원형 테이블에 둘러 앉아서 저녁을 먹는데
  - 모두가 왼쪽에 있는 포크를 먼저 들 고 오른쪽 포크를 들 때, 누구도 식사를 할 수가 없음;;
  - 누군가는 식사를 하고 포크를 내놔야 됨
  - 다익스트라가 마지막 사람은 오른쪽을 먼저 집어라 라고 해놓으면 해결된다고 제시함.

 4) 제마포어
  - 구조체로 만든 세마포어
  - 0보다 작을 수 없게 만든것.

12. Deadlock

 1) Non-Deadlock Bug
  - 원자성 위반 : 걍 앞뒤로 락을 걸어주면 됨.
  - 순서 위반 오류 : 락과 컨디션 변수를 사용하면 됨.  (세마포어를 사용하던지)

 2) Deadlock Bug
  - 데드락은 항상 일어나는게 아니라, 일어날 수도 있고 안 일어날 수도 있다..
  - 스레드1이 L1, L2 락을.. 스레드2가 L2,L1 락을 갖겠다고 했을때 데드락이 일어날 가능성이 있다.
  - '순환 의존성', '캡슐화의 성질' 때문에 일어난다.  

 3) Conditions for Deadlock (교착상태 발생 조건)
  - 상호 배제(Mutual Exclusion) : 쓰레드가 락을 획득한다.
  - 점유 및 대기(Hold-and-Wait) : 할당된 락을 점유한 채 다른 락을 대기한다.
  - 비선점(No preemption) : 락을 점유하고 있는 쓰레드로부터 강제로 못 뺏는다.
  - 환형 대기(Circular wait) : 각 쓰레드는 쓰레드들의 순환 고리가 있다.
  - 위의 4개 중 하나만 해결해도 교착상태는 발생하지 않는다.

 4) Prevention(예방법)
  - 환형 대기(Circular wait) : 전체 순서 또는 부분 순서를 정하는 것 (정렬을 해도 됨, Locking ordering)
  - 점유 및 대기(Hold-and-Wait) : 원자적으로 모든 락을 한번에 획득하도록 한다. (개소리)
  - 비선점(No preemption) : trylock을 사용한다. 획득했던 락을 언락했다가 다시 락함.. 이걸 랜덤성으로 하면됨. (락을 얻으러 여기저기 다녀야할경우 망함)
  - 상호 배제(Mutual Exclusion) : 원자적으로 처리한다. (ex. Compare-and-Swap..)

 5) 스케쥴링을 이용한 Deadlock 회피
  - 스케쥴러가 겹치면 안되겠다는걸 판단하고 회피함.
  - 성능 안좋음
  - 임베디드에서 사용

 6) 발견 및 복구
  - 걍 내비두자. (1년에 한 번 발생하는데 굳이 오버헤드를 만들 필요가?)
  - 발생하면 그냥 재부팅하자 ( 현실적..)
  - 물론 우주비행선 같은 경우는 주의
  - 결론 : 락은 피하는게 좋다.

13. I/O Devices & SSD

 1) 계층 버스
  - 메모리 버스, 범용 IO버스, 주변장치용 IO버스로 3계층으로 나눠져있다.
  - 왜냐하면 짧을수록 빨라지는데, 그러면 공간이 작아지고 비싸지기 때문이다.
  - 이 것을 효율적으로 사용하려면 인터페이스와 내부 구조가 중요하다.
  - 인터페이스는 상태 레지스터, 명령 레지스터, 데이터 레지스터가 작동을 제어한다.
  - 내부 구조는 간단한 몇개의 칩이나 펌웨어로 정의한다.

 2) 상호 동작
  - 현재 상태가 바쁘지 않을 때 까지 Polling 한다.
  - 바쁘지 않으면 데이터 레지스터에 데이터를 작성하고, 범용 레지스터에 common을 작성한다.
  - 또 바쁘지 않을 때 까지 Polling 한다.
  - 그러나 Polling을 한다는 것은 언제 까지 기다려야할지 모르기 때문에 성능이 안좋다.
  - 해결 방법 1 : 인터럽트를 걸어서 다른거 먼저 하라고 한다.
  - 하지만, 문맥교환 비용이 많이 들고, 계속 인터럽트가 걸리면 슬래시닷 현상에 빠질 수 있다. (무한 반복 현상)
  - 해결 방법 2 : 하이브리드 이용. 어느정도 기다리다가 안되겠다 싶으면 인터럽트를 건다.
  - 해결 방법 3 : 병합(Coalescing) 이용. 어느정도 모았다가 인터럽트.
  - 오버헤드는 줄겠지만, 절충 시간을 찾기가 어렵다. (어느정도 모을껀지.)

 3) DMA (직접 메모리 접근 방식)
  - DMA란 CPU와 상관없이 메모리와 디스크가 정보를 주고 받는 기술이다.
  - DMA 엔진에게 데이터 위치와 크기만 넘겨주면 알아서 복사해준다.

 4) OS와 디스크의 상호 작용
  - I/O 명령을 통해 레지스터와 포트를 지정할 수 있다.
  - memory mapped I/O : load, store 명령어로 디스크 장치로 접근할 수 있다.
  - 디스크 드라이버를 이용하여 장치 중립적, 추상적으로 이용할 수 있다.
  - 단점 : 특수 기능 이용이 어려움, 버그가 많음

 5) HDD
  - DB를 참고할 것.....

 6) SSD
  - NAND 플래시 메모리를 이용함.
  - Page : 4~16kb, Block : 128~256kb
  - 어떤 것을 쓰기 전에 지우기 때문에 점점 마모되어 제한적 수명을 갖는다.
  - 속도 : SLC > MLC > TLC   // SMT...SMART 라고 외우면 됨;;
  - 랜덤 접근한다.

14. Files and Directories

 1) 파일과 디렉토리
  - 파일은 바이트의 선형 배열이라고 보면 됨.
  - 각 파일에는 아이노드 번호가 있음.
  - 디렉토리도 아이노드 번호가 있음.
  - 디렉토리는 그냥 파일의 아이노드 번호 리스트와 파일의 이름 리스트만 있을 뿐임.
  - .은 자기 자신이고, ..은 부모임
 
 2) 파일 디스크립터
  - 파일 객체를 가리키는 포인터임.
  - 표준 입력 = 0, 표준 출력 = 1, 표준 에러 = 2
  - 그러므로 3부터 시작함

 3) 여러가지 함수들
  - open() : 파일 여는거, 파일 디스크립터를 반환함.
  - read() : 파일 읽는거, 읽은 바이트 수 반환함.
  - write() : 파일에 쓰는거, fd=1임(출력), 몇글자를 읽었는지 반환함
  - close() : 파일 닫음.
  - lseek() : 현재의 오프셋을 변경시켜 주는 것. 첨부터, 현재부터, 뒤부터 이동 가능
  - fsync() : write 버퍼에 있는 것들을 즉시 기록하는 함수. 강제로 디스크에 쓰게 함.

 4) 여러가지 명령어들
  - strace : 프로그램이 실행되는 동안 호출된 모든 시스템 콜을 추적하여 보여줌
  - rm : 파일 삭제, unlink 라는 시스템 콜을 호출함, 성공하면 0을 반환
  - rm * : 그 디렉토리 파일 다 지움, rm -rf * : 그 디렉토리의 하위 디렉토리의 파일까지 다 지움
  - mkdir : 디렉토리 생성, rmdir : 디렉토리 삭제
  - opendir : 디렉토리를 연다, closedir : 디렉토리를 닫는다.
  - readdir : 디렉토리에 있는 파일을 하나씩 읽는다. dirent 구조체를 반환(direct entry..)

 5) 링크
  - 하드링크 : ln 명령어, 새롭게 파일 또는 디렉토리를 생성한다. 새로운 아이노드를 가진 자료구조가 생김.
  - 하드링크는 원본 파일을 삭제해도 참조가 가능하다.
  - 소프트링크 : ln -s 명령어, 그냥 경로만 연결해주는 파일 또는 디렉토리를 생성한다. 용량이 엄청 낮다.
  - 소프트링크는 원본 파일이 지워지면 연결이 끊어져서 dangling reference 문제가 발생한다.

 6) 마운트
  - 파일 시스템을 만드는 것. (윈도우로 치며 C:, D: 드라이브를 만드는 것)
  - mount 명령어를 이용해서 파일 형식과 생성 위치를 적어주면 된다.
  - 파일시스템은 proc, sysfs, tmp, ext3 등 많이 존재한다.

15. File System Implementation (VSFS)

 1) VSFS(Very Simple File System)
  - 다양한 파일 시스템의 정책을 소개하기 위해 만든 간단한 파일시스템
  - 모든 영역은 4KB의 블럭으로 나눈다. 
  - 메타 데이터 영역 + 데이터 영역으로 이루어진다.

 2) 메타 데이터 영역
  - 슈퍼블럭(S) 1개 : 파일 전체에 대한 정보, 아이노드 개수, 데이터블락 개수, 테이블 시작 위치, 심지어 이 정보들은 중요하기 떄문에 몇개 복사해서 가지고 있다.(매직넘버라고 함)
  - 아이노드 비트맵(i) 1개 : 한 블럭에 32000개의 비트가 들어갈 수 있지만, 사실 130개 정도면 충분하다..
  - 데이터 비트맵(d) 1개
  - 아이노드 테이블 5개 : 아이노드는 256B이므로 1블럭에 16개의 아이노드가 들어갈 수 있다. 5블럭이면 80개의 아이노드 (80개의 파일 등록 가능)

 3) 아이노드 접근
  - 아이노드 넘버로 해당 아이노드가 디스크상 어디 있는지 알 수있다. (섹터 단위로 접근 512B)
  - 직접 포인터 : 아이노드 내의 직접 포인터가 파일의 디스크 블럭 하나를 가리킨다. 이것은 파일 크기 제한이 있다.. (포인터 갯수 * 블럭 크기)
  - 간접 포인터 : 멀티레벨인덱스 기법, 간접 포인터는 포인터들이 저장되어있는 블럭을 가리킨다. (포인터를 위한 블럭이 따로 있는거임..)
  - 보통 직접 포인터 12개 + 간접 포인터 1개. 1블럭에 1024개의 포인터.
  - 즉, 최대 파일 크기 = (12+1024)*4 = 4MB..
  - 이중 간접 포인터를 이용하면 4GB,  삼중 간접 포인터를 이용하면 4TB...
  - root는 무조건 아이노드 넘버가 2이다.

 4) 익스텐트
  - 디스크 상의 한 파일의 위치를 가리키기 위해서는 하나의 포인터와 길이만 표현하면 된다.
  - 장점 : 집약되어 있고, 파일을 연속적으로 배치할 때 잘 작동한다.
  - 단점 : 자유도가 낮다.
  - EXT2, EXT3은 멀티레벨인덱스를 사용하지만, 최근의 EXT4는 익스텐트를 사용한다.

 5) 디렉토리 항목(Directory Entry)
  - 아이노드 넘버, 레코드 길이(4의 배수), 문자열 길이, 이름문자열로 구성된다.
  - 만약 파일이 삭제되면 아이노드 넘버를 0으로 바꾸고 문자열 길이를 수정시키고, 나중에 새로운 항목을 위치시킨다.

 6) 디렉토리 형식(Directory Type)
  - 디렉토리도 마찬가지로 아이노드 테이블에 기록되는데, type에 d라고 적힘.
  - xfs 형식은 b-tree 형식으로 구성되어 파일 검색이 빠르다..
  - FAT은 연결리스트를 사용한 방법으로 굉장히 느리고 하드 링크 만드는것도 불가능하다 (옛날 방식)

16. Fast File System

 1) Old File System
  - 성능이 너무 느리다. 마치 RAM처럼 랜덤 접근을 하기에 하드디스크의 지역성을 전혀 이용하지 못한다.
  - 아이노드와 데이터 영역이 서로 붙어있게끔 만들면 좋을 것 같다.
  - 빈공간을 관리하지 않아서 단편화가 심하다.. (조각 모음 도구를..)
  - 블럭의 크기가 너무 작다. 블럭의 크기가 작으면 디스크로 너무 많이 왔다갔다

 2) Fast File System
  - 인터페이스는 유지하면서, 하드디스크에 적합하게 바꾸다.
  - 실린더 그룹 : 파일과 그 파일이 속한 디렉토리 블럭을 같은 그룹에 할당.
  - 긴 탐색 방지 : 아이노드와 파일의 데이터 블럭을 같은 그룹에 할당.

 3) SEER 트레이스 거리 측정
  - 같은 파일일 때는 0이고, 같은 디렉터리의 다른 파일은 1임.
  - 즉, 트리의 얼만큼 올라가는지로 계산
  - 0과 1이 40%를 차지, 2가 25% 차지... (지역성이 존재한다는 사실을 증명)

 4) 기타 고려 사항
  - 서브블럭 : 작은 것들을 임시로 모아두는 작은 블럭 (512KB), 내부 단편화가 많이 발생함..
  - 매개화 : 디스크 헤드 시차를 고려하여 배치를 바꾼다, 물론 요즘은 디스크 캐시에 버퍼링해버림..
  - 긴 파일 이름 : 예전에는 8글자.. 요즘은 굳..

17. Crash Consistency : FSCK and Journaling

 1) Crash Consistency Problem
  - 파일 끝에 새로운 글을 썼을 경우 아이노드 사이즈, 직접포인터, 데이터 비트맵, 데이터 블락 등에 모두 변화가 일어나야 한다.
  - 디스크는 한 번에 하나의 처리 밖에 못하므로 페이지 캐시나 버퍼 캐시에 잠시 있다가 5초 정도 후에 실행이 된다.
  - 하지만 갑자기 정전이 나거나 오류가 나서 문제가 생길 수 있다.

 2) Crash Consistency 시나리오
  - 데이터 블록만 기록됨 : 일관성은 유지, 데이터 손실 발생 (걍 덮어 씌우면 되거든)
  - 아이노드만 기록됨 : 일관성 손상, 보안 문제 ( 이상한 곳을 가리키거든)
  - 비트맵만 기록됨 : 일관성 손상, 영영 사용 못함 (접근이 불가..)
  - 아이노드+비트맵 기록됨 : 일관성 유지, 보안 문제
  - 아이노드+데이터 블록 기록됨 : 일관성 손상
  - 비트맵+데이터 블록 기록됨 : 일관성 손상, 파일 소속을 모름

 3) FSCK(File System Checker, 파일 시스템 검사기)
  - 파일 시스템의 일관성 불일치를 발견하고 수정하는 유닉스 도구
  - 단점 1 : 일관성은 유지되지만 데이터 손실 문제는 해결 못함 (데이터 블록, 아이노드+비트맵)
  - 슈퍼블록 검사, 아이노드 검사, 중복 검사, 디렉토리 검사, 배드 블럭 검사, 프리 블럭 검사...
  - 단점 2 : 너무 느리다.. 1층에서 열쇠 잃어버리고 빌딩 전체를 찾는 격..

 4) 저널링( = Write-Ahead Logging)
  - 디스크 내용을 갱신할 때, 미리 요약해서 로그를 딴 데다 기록해둔다.
  - 크래쉬가 나면 로그를 다시 RE-DO.
  - 단점 : 평소에 쓰기 작업이 느려진다. ( but, 오버헤드가 굉장히 적어서 상관X)
  - 저널은 보통 파일시스템 포맷시에 공간을 설정한다. (ex. 128MB)
  - 체크포인팅 : 저널에 기록된 내용을 실제 위치에 반영하는 과정
  - 저널 하다가 크래쉬 나면 걍 첨부터 다시 시작.
  - 메타 데이터만 저널링 하는게 좋음.
